{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stafflink=[]\n",
    "stafflinks = []\n",
    "names = []\n",
    "area = []\n",
    "links= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.sunderland.ac.uk/about/staff/computing/\")\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "for main in soup.find('section',class_='staff_results').find_all('li'):\n",
    "    try:\n",
    "        slist = main.a['href']\n",
    "    except Exception as e:\n",
    "        slist = None\n",
    "    stafflinks.append(slist)\n",
    "    stafflink = list(filter(None,stafflinks)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ppage in stafflink:\n",
    "    ppages = requests.get(str(ppage))\n",
    "    sp = BeautifulSoup(ppages.text, 'html.parser')\n",
    "    try:\n",
    "        sname=sp.find('div', class_='page--title').h1.text\n",
    "    except Exception as e:\n",
    "        sname = 'None'\n",
    "    names.append(sname)\n",
    "    \n",
    "    try:\n",
    "        sarea= sp.find_all(attrs={\"data-smile-tab\": \"2\"})[0].p.text\n",
    "    except Exception as e:\n",
    "        sarea = 'None'\n",
    "    area.append(sarea)\n",
    "    \n",
    "    slink = (str(ppage))\n",
    "    links.append(slink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni1 = pd.DataFrame({\n",
    "'title': names,\n",
    "'link':links,\n",
    "'summary': area\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [] \n",
    "phone = []\n",
    "links = []\n",
    "emails = []\n",
    "area = []\n",
    "pages = [\"computing\"]\n",
    "for page in pages:\n",
    "    page = requests.get(\"https://www.imperial.ac.uk/\" + str(page) + \"/people/academic-staff/\")\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    title = soup.find('div', class_='module')\n",
    "    for staffpages in title.find_all('li'):\n",
    "        try:\n",
    "            nn = staffpages.h3.text\n",
    "        except Exception as e:\n",
    "            nn = None\n",
    "        name.append(nn)\n",
    "        names = staffpages.find('div', class_='name-wrapper')\n",
    "        try:\n",
    "            num = names.p.span.text\n",
    "        except Exception as e:\n",
    "            num = 'no'\n",
    "        phone.append(num)\n",
    "        try:\n",
    "            link = names.a['href']\n",
    "        except Exception as e:\n",
    "            link = None\n",
    "        links.append(link)\n",
    "        try:\n",
    "            email = list.p.a['href'].split(':')[1]\n",
    "        except Exception as e:\n",
    "            email = None\n",
    "        emails.append(email)  \n",
    "        des = staffpages.find('div', class_='dept-wrapper')\n",
    "        try:\n",
    "            desc = des.p.span.text\n",
    "        except Exception as e:\n",
    "            desc = 'u'\n",
    "        area.append(desc)\n",
    "uni2 = pd.DataFrame({\n",
    "'title': name,\n",
    "'link':links,\n",
    "'summary': area\n",
    "})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stafflink=[]\n",
    "names = []\n",
    "area = []\n",
    "links= []\n",
    "page = requests.get(\"http://www.chem.ed.ac.uk/staff/academic-staff\")\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "for main in soup.find_all('td', class_='views-field views-field-title'):\n",
    "    try:\n",
    "        staffpage = main.a['href']\n",
    "    except Exception as e:\n",
    "        staffpage = 'nah'\n",
    "    stafflink.append(staffpage)\n",
    "for ppage in stafflink:\n",
    "    ppages = requests.get(\"http://www.chem.ed.ac.uk\" + str(ppage))\n",
    "    soupp = BeautifulSoup(ppages.text, 'html.parser')\n",
    "    try:\n",
    "        aa= soupp.find_all('div', class_='pane-content')[5].text \n",
    "    except Exception as e:\n",
    "        aa = 'pass'    \n",
    "    area.append(aa)\n",
    "    name = soupp.title.text.split('|')[0]\n",
    "    names.append(name)\n",
    "    link = (\"http://www.chem.ed.ac.uk\" + str(ppage)) \n",
    "    links.append(link)\n",
    "uni3= pd.DataFrame({\n",
    "'title': names,\n",
    "'link':links,\n",
    "'summary': area\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni =[uni1,uni2, uni3]\n",
    "resii = pd.concat(uni)\n",
    "resii['ID'] = [x for x in range(1, len(resii.values)+1)]\n",
    "resii.to_csv('univerity1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>summary</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Andrew Smith</td>\n",
       "      <td>https://www.sunderland.ac.uk/about/staff/compu...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Professor Yonghong Peng</td>\n",
       "      <td>https://www.sunderland.ac.uk/about/staff/compu...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Elizabeth A. Gandy</td>\n",
       "      <td>https://www.sunderland.ac.uk/about/staff/compu...</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Chris Knowles</td>\n",
       "      <td>https://www.sunderland.ac.uk/about/staff/compu...</td>\n",
       "      <td>\\nKnowles, Christopher, Kok, Dirk, Baglee, Dav...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Stephen Swales</td>\n",
       "      <td>https://www.sunderland.ac.uk/about/staff/compu...</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                    title  \\\n",
       "0           0             Andrew Smith   \n",
       "1           1  Professor Yonghong Peng   \n",
       "2           2       Elizabeth A. Gandy   \n",
       "3           3            Chris Knowles   \n",
       "4           4           Stephen Swales   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.sunderland.ac.uk/about/staff/compu...   \n",
       "1  https://www.sunderland.ac.uk/about/staff/compu...   \n",
       "2  https://www.sunderland.ac.uk/about/staff/compu...   \n",
       "3  https://www.sunderland.ac.uk/about/staff/compu...   \n",
       "4  https://www.sunderland.ac.uk/about/staff/compu...   \n",
       "\n",
       "                                             summary  ID  \n",
       "0                                               None   1  \n",
       "1                                               None   2  \n",
       "2                                               None   3  \n",
       "3  \\nKnowles, Christopher, Kok, Dirk, Baglee, Dav...   4  \n",
       "4                                               None   5  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data = pd.read_csv(\"univerity.csv\")\n",
    "meta_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\presh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\presh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\presh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\presh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "covus = meta_data.loc[0,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                    0\n",
       "title                                              Andrew Smith\n",
       "link          https://www.sunderland.ac.uk/about/staff/compu...\n",
       "summary                                                    None\n",
       "ID                                                            1\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_string(text):\n",
    "  text = text.lower() #to lowercase\n",
    "  text = text.translate(str.maketrans('', '', string.punctuation)) #strip punctuation\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' andrew smith'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_string(covus.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orange: n\n",
      " is: v\n",
      " lovely: r\n"
     ]
    }
   ],
   "source": [
    "print(\"Orange: {}\\n is: {}\\n lovely: {}\" \n",
    "      .format(get_wordnet_pos(\"Orange\"),\n",
    "         get_wordnet_pos(\"is\"), \n",
    "        get_wordnet_pos(\"lovely\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "\n",
    "def stop_lemmatize(doc):\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    tmp = \"\"\n",
    "    for w in tokens:\n",
    "        if w not in stop:\n",
    "            tmp += lem.lemmatize(w, get_wordnet_pos(w)) + \" \"\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Andrew Smith '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_lemmatize(doc = covus.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_string(text):\n",
    "  text = text.lower() #to lowercase\n",
    "  text = text.translate(str.maketrans('', '', string.punctuation)) #strip punctuation\n",
    "  text = stop_lemmatize(text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'andrew smith '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time process_string(covus.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_processed = meta_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(df):\n",
    "  df['title'] = df['title'].apply(process_string)\n",
    "  df['summary'] = df['summary'].apply(process_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.96 s\n"
     ]
    }
   ],
   "source": [
    "%time transform_df(meta_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>summary</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>andrew smith</td>\n",
       "      <td>https://www.sunderland.ac.uk/about/staff/compu...</td>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>professor yonghong peng</td>\n",
       "      <td>https://www.sunderland.ac.uk/about/staff/compu...</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>elizabeth gandy</td>\n",
       "      <td>https://www.sunderland.ac.uk/about/staff/compu...</td>\n",
       "      <td>none</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>chris knowles</td>\n",
       "      <td>https://www.sunderland.ac.uk/about/staff/compu...</td>\n",
       "      <td>knowles christopher kok dirk baglee david morr...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>stephen swale</td>\n",
       "      <td>https://www.sunderland.ac.uk/about/staff/compu...</td>\n",
       "      <td>none</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                     title  \\\n",
       "0           0             andrew smith    \n",
       "1           1  professor yonghong peng    \n",
       "2           2          elizabeth gandy    \n",
       "3           3            chris knowles    \n",
       "4           4            stephen swale    \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.sunderland.ac.uk/about/staff/compu...   \n",
       "1  https://www.sunderland.ac.uk/about/staff/compu...   \n",
       "2  https://www.sunderland.ac.uk/about/staff/compu...   \n",
       "3  https://www.sunderland.ac.uk/about/staff/compu...   \n",
       "4  https://www.sunderland.ac.uk/about/staff/compu...   \n",
       "\n",
       "                                             summary  ID  \n",
       "0                                              none    1  \n",
       "1                                              none    2  \n",
       "2                                              none    3  \n",
       "3  knowles christopher kok dirk baglee david morr...   4  \n",
       "4                                              none    5  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_processed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_processed['text'] = meta_processed['title'] + \" \" + meta_processed['summary']\n",
    "drop_cols = ['title', 'summary', 'link']\n",
    "meta_processed = meta_processed.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>andrew smith  none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>professor yonghong peng  none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>elizabeth gandy  none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>chris knowles  knowles christopher kok dirk ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>stephen swale  none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>49</td>\n",
       "      <td>151</td>\n",
       "      <td>dr uwe schneider  ‘ greensustainable ’ chemist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>50</td>\n",
       "      <td>152</td>\n",
       "      <td>professor michael seery  chemistry education t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>51</td>\n",
       "      <td>153</td>\n",
       "      <td>dr rafal szabla  computational theoretical che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>52</td>\n",
       "      <td>154</td>\n",
       "      <td>dr stephen p thomas  catalysis organometallic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>53</td>\n",
       "      <td>155</td>\n",
       "      <td>professor dusan uhrin  nmr spectroscopy mass s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   ID                                               text\n",
       "0             0    1                                andrew smith  none \n",
       "1             1    2                     professor yonghong peng  none \n",
       "2             2    3                             elizabeth gandy  none \n",
       "3             3    4  chris knowles  knowles christopher kok dirk ba...\n",
       "4             4    5                               stephen swale  none \n",
       "..          ...  ...                                                ...\n",
       "150          49  151  dr uwe schneider  ‘ greensustainable ’ chemist...\n",
       "151          50  152  professor michael seery  chemistry education t...\n",
       "152          51  153  dr rafal szabla  computational theoretical che...\n",
       "153          52  154  dr stephen p thomas  catalysis organometallic ...\n",
       "154          53  155  professor dusan uhrin  nmr spectroscopy mass s...\n",
       "\n",
       "[155 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(df):\n",
    "  df = df\n",
    "  df['title'] = df['title'].apply(process_string)\n",
    "  df['summary'] = df['summary'].apply(process_string)\n",
    "  df['text'] = df['title'] + \" \" + df['summary']\n",
    "  drop_cols = ['title', 'summary', 'link']\n",
    "  df = df.drop(drop_cols, axis=1)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                                  10\n",
      "ID                                          41\n",
      "text          dr yvesalexandre de montjoye  u \n",
      "Name: 40, dtype: object\n"
     ]
    }
   ],
   "source": [
    "covus = meta_processed.loc[40,:].copy()\n",
    "print(covus)\n",
    "index_test = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = covus.text.split()\n",
    "ID = covus.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dr': [41]}\n"
     ]
    }
   ],
   "source": [
    "word = words[0]\n",
    "sample = {word: [ID]}\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words:\n",
    "  if word in index_test.keys():\n",
    "    if ID not in index_test[word]:\n",
    "      index_test[word].append(ID)\n",
    "  else:\n",
    "    index_test[word] = [ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dr': [41], 'yvesalexandre': [41], 'de': [41], 'montjoye': [41], 'u': [41]}\n"
     ]
    }
   ],
   "source": [
    "print(index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_it(covus, index):\n",
    "  words = covus.text.split()\n",
    "  ID = covus.ID\n",
    "  for word in words:\n",
    "    if word in index.keys():\n",
    "      if ID not in index[word]:\n",
    "        index[word].append(ID)\n",
    "    else:\n",
    "      index[word] = [ID]\n",
    "  return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dr': [41], 'yvesalexandre': [41], 'de': [41], 'montjoye': [41], 'u': [41]}\n"
     ]
    }
   ],
   "source": [
    "ind = index_it(covus=covus, index= {})\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_all(df, index):\n",
    "  for i in range(len(df)):\n",
    "    entry = df.loc[i,:]\n",
    "    index = index_it(covus = covus, index = index)\n",
    "  return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = index_all(meta_processed, index = {})\n",
    "len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index(df, index):\n",
    "    to_add = transform_df(df)\n",
    "    index = index_all(df = to_add, index = index)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = build_index(df = meta_data, index = {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dr': [41], 'yvesalexandre': [41], 'de': [41], 'montjoye': [41], 'u': [41]}\n"
     ]
    }
   ],
   "source": [
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dr', 'yvesalexandre', 'de', 'montjoye', 'u']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_vectors(word2vec_model, doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc if word in word2vec_model.vocab]\n",
    "    if len(doc) == 0:\n",
    "      return np.zeros(300)\n",
    "    else:\n",
    "      return np.mean(word2vec_model[doc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.8 s\n",
      "Parser   : 603 ms\n"
     ]
    }
   ],
   "source": [
    "%time test_vec = average_vectors(word2vec, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ranking(df):\n",
    "  corpus = df[['ID', 'text']].copy()\n",
    "  doc_vecs = {}\n",
    "  for i in range(len(corpus)):\n",
    "    row = corpus.loc[i,:]\n",
    "    text = row.text.split()\n",
    "    doc_vecs[row.ID]=average_vectors(word2vec, text)\n",
    "  doc_vecs = pd.DataFrame.from_dict(data=doc_vecs, orient=\"index\")\n",
    "  doc_vecs['ID'] = doc_vecs.index\n",
    "  return doc_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vecs = prepare_ranking(df=meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"formal method\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"User query: {}.\" .format(test))\n",
    "test_norm = process_string(test)\n",
    "print(\"Normalized query: {}.\" .format(test_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = test_norm.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "  norm = process_string(query)\n",
    "  return norm.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved = []\n",
    "for word in test_split:\n",
    "  if word in index.keys():\n",
    "    retrieved.append(index[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lists_intersection(lists):\n",
    "  intersect = list(set.intersection(*map(set, lists)))\n",
    "  intersect.sort()\n",
    "  return intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lists_intersection(retrieved)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_googleish(query, index=idx):\n",
    "  query_split = process_query(query)\n",
    "  retrieved = []\n",
    "  for word in query_split:\n",
    "    if word in index.keys():\n",
    "      retrieved.append(index[word])\n",
    "  if len(retrieved)>0:\n",
    "    result = lists_intersection(retrieved)\n",
    "  else:\n",
    "      result = [0]\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_IDs = search_googleish(\"dr\", index)\n",
    "print(result_IDs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta_data.drop(['text'], axis=1).copy()\n",
    "meta.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_id_df(retrieved_id, df):\n",
    "    return df[df.ID.isin(retrieved_id)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_meta = connect_id_df(result_IDs, meta)\n",
    "result_meta.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vec = average_vectors(word2vec, test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_vecs = connect_id_df(result_IDs, doc_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(a, b):\n",
    "  dot = np.dot(a, b)\n",
    "  norma = np.linalg.norm(a)\n",
    "  normb = np.linalg.norm(b)\n",
    "  cos = dot / (norma * normb)\n",
    "  return(cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = []\n",
    "for i in range(len(result_vecs)):\n",
    "  doc_vec = result_vecs.loc[i,:].drop(['ID'])\n",
    "  cos_sim.append(cos_similarity(doc_vec, query_vec))\n",
    "result_meta['rank'] = cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_meta.sort_values('rank', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_results(query, results):\n",
    "  query_norm = process_query(query)\n",
    "  query_vec = average_vectors(word2vec, query_norm)\n",
    "  result_vecs = connect_id_df(results.ID, doc_vecs)\n",
    "  cos_sim = []\n",
    "  for i in range(len(result_vecs)):\n",
    "    doc_vec = result_vecs.loc[i,:].drop(['ID'])\n",
    "    cos_sim.append(cos_similarity(doc_vec, query_vec))\n",
    "  results['rank'] = cos_sim\n",
    "  results = results.sort_values('rank', axis=0)\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = rank_results(\"john lewis\", result_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(result_df):\n",
    "  for i in range(len(result_df)):\n",
    "    res = result_df.loc[i, :]\n",
    "    print(res.title)\n",
    "    print(res.summary)\n",
    "    if i == len(result_df):\n",
    "        print(res.link)\n",
    "    else:\n",
    "        print(\"{}\\n\" .format(res.link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, dat=None):\n",
    "  result = search_googleish(query)\n",
    "  result = connect_id_df(result, meta)\n",
    "  result = rank_results(query, result)\n",
    "\n",
    "  if dat is not None:\n",
    "    result = filter_date(dat, result)\n",
    "\n",
    "  print_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = input(\"Search for:\")\n",
    "search(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
